name: CloudStream Multi Branch Updater

on:
  schedule:
    - cron: '0 21 * * *'
  workflow_dispatch:

jobs:
  aggregate_main:
    name: Aggregate from main/master branches
    runs-on: ubuntu-latest

    steps:
      - name: Checkout your own repo (default branch)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up work directory
        run: |
          mkdir -p sources
          rm -rf sources/*

      - name: Clone external repos (default branch)
        run: |
          git clone --depth=1 https://github.com/GitLatte/repos.git sources/repos

      - name: Aggregate files except plugins.json and repo.json
        run: |
          set -e
          shopt -s globstar
          repos=(sources/repos)
          dest=aggregated
          rm -rf "$dest"
          mkdir -p "$dest"
          declare -A filemap
          for repo in "${repos[@]}"; do
            cd "$GITHUB_WORKSPACE/$repo"
            for file in $(find . -type f ! -name 'plugins.json' ! -name 'repo.json'); do
              realfile="$PWD/$file"
              cdate=$(git log -1 --format="%ct" -- "$file" 2>/dev/null || echo 0)
              key="${file#./}"
              if [[ -z "${filemap[$key]}" || "$cdate" -gt "${filemap[$key]%%:*}" ]]; then
                filemap[$key]="$cdate:$realfile"
              fi
            done
            cd "$GITHUB_WORKSPACE"
          done
          for key in "${!filemap[@]}"; do
            src="${filemap[$key]#*:}"
            dest_file="$dest/$key"
            mkdir -p "$(dirname "$dest_file")"
            if [ -f "$src" ]; then
              cp "$src" "$dest_file"
            fi
          done

      - name: Merge plugins.json from all sources and set authors
        run: |
          python3 - <<EOF
import os, json

plugin_candidates = dict()
sources = os.listdir("sources")
for entry in sources:
    repo = f"sources/{entry}"
    plugin_json = f"{repo}/plugins.json"
    if os.path.isfile(plugin_json):
        try:
            mtime = os.path.getmtime(plugin_json)
            with open(plugin_json, encoding="utf-8") as f:
                plugins = json.load(f)
        except Exception:
            continue
        if isinstance(plugins, dict):
            plugins = plugins.get("plugins", [])
        elif not isinstance(plugins, list):
            plugins = []
        for plugin in plugins:
            key = plugin.get("id") or plugin.get("name") or json.dumps(plugin, sort_keys=True)
            if key not in plugin_candidates or mtime > plugin_candidates[key][0]:
                plugin_candidates[key] = (mtime, plugin)
output = []
for _, plugin in plugin_candidates.values():
    plugin["authors"] = ["WantedGang"]
    output.append(plugin)
os.makedirs("aggregated", exist_ok=True)
with open("aggregated/plugins.json", "w", encoding="utf-8") as f:
    json.dump(output, f, ensure_ascii=False, indent=2)
EOF

      - name: Replace repo.json with your own
        run: |
          [ -f repo.json ] && cp -f repo.json aggregated/repo.json

      - name: Clean up current repo (except .git and workflow)
        run: |
          shopt -s extglob
          rm -rf !(.git|.github|aggregated)

      - name: Move aggregated files into repo root
        run: |
          if [ -d aggregated ] && [ "$(ls -A aggregated)" ]; then
            cp -r aggregated/* .
          fi
          rm -rf aggregated sources

      - name: Commit and push changes (default branch)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git status
          git diff --cached --quiet || git commit -m "Aggregate CloudStream sources from default branches (auto sync)"
          git push

  aggregate_builds:
    name: Aggregate from builds branches
    runs-on: ubuntu-latest

    steps:
      - name: Checkout your own repo (builds branch)
        uses: actions/checkout@v4
        with:
          ref: builds
          fetch-depth: 0

      - name: Set up work directory
        run: |
          mkdir -p sources
          rm -rf sources/*

      - name: Clone external repos (builds branch only)
        run: |
          git clone --depth=1 --single-branch --branch builds https://github.com/GitLatte/repos.git sources/repos || true
          

      - name: Aggregate files except plugins.json and repo.json
        run: |
          set -e
          shopt -s globstar
          repos=(sources/repos)
          dest=aggregated
          rm -rf "$dest"
          mkdir -p "$dest"
          declare -A filemap
          for repo in "${repos[@]}"; do
            if [ -d "$GITHUB_WORKSPACE/$repo" ]; then
              cd "$GITHUB_WORKSPACE/$repo"
              for file in $(find . -type f ! -name 'plugins.json' ! -name 'repo.json'); do
                realfile="$PWD/$file"
                cdate=$(git log -1 --format="%ct" -- "$file" 2>/dev/null || echo 0)
                key="${file#./}"
                if [[ -z "${filemap[$key]}" || "$cdate" -gt "${filemap[$key]%%:*}" ]]; then
                  filemap[$key]="$cdate:$realfile"
                fi
              done
              cd "$GITHUB_WORKSPACE"
            fi
          done
          for key in "${!filemap[@]}"; do
            src="${filemap[$key]#*:}"
            dest_file="$dest/$key"
            mkdir -p "$(dirname "$dest_file")"
            if [ -f "$src" ]; then
              cp "$src" "$dest_file"
            fi
          done

      - name: Merge plugins.json from all sources and set authors
        run: |
          python3 - <<EOF
import os, json

plugin_candidates = dict()
sources = os.listdir("sources")
for entry in sources:
    repo = f"sources/{entry}"
    plugin_json = f"{repo}/plugins.json"
    if os.path.isfile(plugin_json):
        try:
            mtime = os.path.getmtime(plugin_json)
            with open(plugin_json, encoding="utf-8") as f:
                plugins = json.load(f)
        except Exception:
            continue
        if isinstance(plugins, dict):
            plugins = plugins.get("plugins", [])
        elif not isinstance(plugins, list):
            plugins = []
        for plugin in plugins:
            key = plugin.get("id") or plugin.get("name") or json.dumps(plugin, sort_keys=True)
            if key not in plugin_candidates or mtime > plugin_candidates[key][0]:
                plugin_candidates[key] = (mtime, plugin)
output = []
for _, plugin in plugin_candidates.values():
    plugin["authors"] = ["WantedGang"]
    output.append(plugin)
os.makedirs("aggregated", exist_ok=True)
with open("aggregated/plugins.json", "w", encoding="utf-8") as f:
    json.dump(output, f, ensure_ascii=False, indent=2)
EOF

      - name: Replace repo.json with your own
        run: |
          [ -f repo.json ] && cp -f repo.json aggregated/repo.json

      - name: Clean up current repo (except .git and workflow)
        run: |
          shopt -s extglob
          rm -rf !(.git|.github|aggregated)

      - name: Move aggregated files into repo root
        run: |
          if [ -d aggregated ] && [ "$(ls -A aggregated)" ]; then
            cp -r aggregated/* .
          fi
          rm -rf aggregated sources

      - name: Commit and push changes (builds branch)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git status
          git diff --cached --quiet || git commit -m "Aggregate CloudStream sources from builds branches (auto sync)"
          git push
